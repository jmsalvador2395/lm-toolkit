#!/usr/bin/env python

import argparse
import re
import os
import json
from scipy.stats import kendalltau
import numpy as np
from tqdm import tqdm

from IPython.terminal.embed import InteractiveShellEmbed

def hinge_pair_loss(data, margin=1):
    labels, scores, preds = zip(*data)
    labels = np.vstack(labels)
    scores = np.vstack(scores)
    preds = np.vstack(preds)

    N, L = labels.shape

    reverse = np.argsort(labels, axis=-1)
    X = np.arange(N)[None].T.repeat(L, axis=-1)
    or_scores = scores[X, reverse.astype(int)]
    loss = np.maximum(0, margin + or_scores[:, :-1] - or_scores[:, 1:])

    return loss

def masked_hinge_pair_loss(data, margin=1):
    labels, scores, preds = zip(*data)
    labels = np.vstack(labels)
    scores = np.vstack(scores)
    preds = np.vstack(preds)

    N, L = labels.shape

    reverse = np.argsort(labels, axis=-1)
    X = np.arange(N)[None].T.repeat(L, axis=-1)
    #jor_scores = scores[X, reverse.astype(int)]
    or_scores = scores[X, labels.astype(int)]
    loss = np.maximum(0, margin + or_scores[:, :-1] - or_scores[:, 1:])

    wrong_mask = (labels != preds)
    wrong_mask = wrong_mask[X, reverse]
    left = np.cumsum(wrong_mask, axis=-1)
    right = np.fliplr(np.cumsum(np.fliplr(wrong_mask), axis=-1))
    wrong_mask = (left*right).astype(bool)
    loss = loss*(wrong_mask[:, :-1] & wrong_mask[:, 1:])

    return loss


def get_losses(data, margin):
    loss = {
        key: masked_hinge_pair_loss(data[key], margin) 
        for key in data.keys()
    }
    return loss

def get_metrics(data):
    pmr = dict()
    acc = dict()
    tau = dict()

    for key, dt in tqdm(data.items()):
        labels, scores, pred = zip(*dt)
        labels = np.array(labels)
        scores = np.array(scores)
        pred = np.array(pred)

        tau[key] = np.array([
            kendalltau(*pair).statistic 
            for pair in zip(labels, np.argsort(scores))
        ])
        eq = labels == pred
        acc[key] = np.mean(eq)
        pmr[key] = np.mean(np.all(eq, axis=-1))
    return pmr, acc, tau

def get_splits(data):
    labels, scores, preds = zip(*data)
    return np.array(labels), np.array(scores), np.array(preds)

def main(args):
    path = args.path
    fnames = os.listdir(path)
    fpaths = list(map(lambda x: f'{path}/{x}', fnames))
    keys = [
        int(re.match(r'step-(\d+)\.json', fname).groups()[0]) 
        for fname in fnames
    ]
    data = {}
    for fpath, num in zip(fpaths, keys):
        with open(fpath) as f:
            data[num] = json.loads(f.read())
    odata = {}
    for key in tqdm(data.keys()):
        odata[key] = []
        for labels, preds in data[key]:
            odata[key].append([
                np.array(labels), np.array(preds), 
                np.argsort(np.array(preds))
            ])
    data = odata

    keys = sorted(keys)
    key = keys[-1]
    print(keys)
    loss = get_losses(data, margin=1)
    pmr, acc, tau = get_metrics(data)
    #N = len(data[keys[-1]])

    labels, scores, preds = get_splits(data[key])
    N, L = labels.shape
    X = np.arange(N)[None].T.repeat(5, axis=-1)
    rev = np.argsort(labels, axis=-1)

    res = labels != preds
    res_or = res[X, rev]
    hits = np.where(np.any(res, axis=-1))[0]
    
    ipshell = InteractiveShellEmbed()
    ipshell()
    

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '-p', '--path', type=str, help='target directory', default='./'
    )
    args = parser.parse_args()
    main(args)