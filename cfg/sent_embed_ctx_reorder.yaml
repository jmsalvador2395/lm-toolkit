paths:
  logdir_base: "{{project_root}}/tensorboard"
  cache: "/data/john/cache"
  results: "{{project_root}}/results"
  
general: 
  task: "sent_emb_ctx_reorder"
  seed: null
  note: "Without MLP last layer"

params:
  save_criterion: "max"
  save_checkpoint: False
  patience: 2

  # model params
  #encoder: "mixedbread-ai/mxbai-embed-large-v1"
  encoder: "facebook/bart-large"
  freeze_encoder: False
  d_model: 1024
  nhead: 16
  dim_feedforward: 1024
  #dim_feedforward: 1024
  dropout: 0.1
  activation: 'gelu'
  sent_len: 128
  seq_len: 512
  with_positions: True
  num_xformer_layers: 1
  mlp_hidden_dim: 4096
  #mlp_hidden_dim: 1024
  num_mlp_layers: 0
  method: 'regression'
  dtype: "float32"

  # loss args
  loss_fn: "hinge_pair"
  margin: 5
  scale: 5
  alpha: .6283707401

  # optimizer params
  lr: 1.7370388368850602e-06
  encoder_lr: 2.8301354960834736e-06
  weight_decay: 1.0e-6
  encoder_weight_decay: 1.0e-6
  beta1: .9
  beta2: .999
  eps: 1.0e-8
  clip_max_norm: 1

  # optimizer scheduler
  sched_step_size: 5
  sched_gamma: 0.95

  # data params
  num_proc: 10
  shuffle: True
  batch_size: 96
  num_epochs: 15
  eval_freq: 300
  log_freq: 50
  num_test_samples: 25
  dataset: "all"

  # misc options
  skip_first_eval: True

# Used for hyperparameter search.
# For each parameter, if "num_samples" isn't specified, 
# only the values specificed in the "values" argument will be used
search_params:
  search_type: 'random'
  search_steps: 240
  train_step_limit: null
  weight_decay:
    values: [1.0e-6, 1.0e+2]
    dtype: "float"
    scale: "log"
  encoder_weight_decay:
    values: [1.0e-6, 1.0e+2]
    dtype: "float"
    scale: "log"
  lr: 
    values: [1.0e-6, 1.0e-3]
    num_samples: 10
    dtype: "float"
    scale: "log"
  encoder_lr: 
    values: [1.0e-6, 1.0e-4]
    num_samples: 10
    dtype: "float"
    scale: "log"
  # num_xformer_layers:
  #   values: [1, 4, 8]
  #   dtype: "int"
  # dim_feed_forward:
  #   values: [1024, 4096, 8192]
  #   dtype: "int"
  margin:
    values: [1, 3, 5]
    dtype: "float"
  batch_size:
    values: [32, 64, 96]
    dtype: "int"