general: 
    trainer: "sofsat-ranking-dcg"
    seed: 123
    logdir_base: "{{project_root}}/tensorboard"
    note: "test"

model:
    ckpt_dir: "{{project_root}}/checkpoints"
    save_checkpoint: True
    keep_higher_eval: True
    #load_checkpoint: "/data/john/projects/mltoolkit/debug/ckpt/checkpoint.pt"

    # LSTM parameters
    dim_feed_forward: 1024
    out_size: 10
    mlp_dropout: .05
    decoder_dropout: .05
    num_decoder_layers: 2
    mlp_layers: 4
    device: "cuda:2"

    # reward model params
    reward_model: 'all-mpnet-base-v1'
    reward_device: "cuda:3"
    reward_batch_size: 100

optim:
    lr: 9.0e-6
    weight_decay: 1.0e-5
    beta1: .9
    beta2: .999
    eps: 1.0e-8
    clip_max_norm: 1.5

    # optimizer scheduler
    sched_step_size: 200
    sched_gamma: 0.99

    # swa scheduler
    swa_begin: -10
    swa_strat_is_linear: True
    swa_anneal_epochs: 5
    swa_lr: 0.05
    swa_bn_update_steps: "all"

data: 
    loc: "{{project_root}}/data/all_sides/all_sides.csv"
    num_proc: 0
    pin_memory: False
    num_shards: 1
    cache_dir: "{{home}}/.cache/huggingface"
    shuffle: True
    batch_size: 64
    num_epochs: 1500
    eval_freq: 50
    log_freq: 1
    train_test_split: .85
    tokenizer_name: "distilbert"
    commute_prob: 0.5
    max_seq_len: 512
    n_docs: 2
    data_device: "cuda:3"
    embedder_batch_size: 100
    doc_model: "all-mpnet-base-v1"
    use_cls_embs: False
    limit_sentences: True
    max_sentences_per_doc: 256
